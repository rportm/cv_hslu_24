{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation of Multiple Sclerosis with Brain MRI dataset"
      ],
      "metadata": {
        "id": "yjcgwoCAWQ-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Jupyter notebook is designed to explore and utilize a Brain MRI dataset of patients with Multiple Sclerosis (MS) for the purpose of predicting lesions. Multiple Sclerosis is a chronic illness characterized by the presence of lesions in the brain and spinal cord, leading to a wide range of neurological symptoms. Detecting and monitoring these lesions using MRI is a critical part of diagnosing and managing the disease.\n",
        "\n",
        "The dataset used in this notebook is sourced from a research publication by M Muslim (2022) and includes MRI scans along with consensus manual lesion segmentation. This provides an adequate resource for training and evaluating AI models in medical imaging applications.\n"
      ],
      "metadata": {
        "id": "3XfLHbelWjXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "94JIDVBZW1uE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will download the Brain MRI dataset from the Mendeley Data repository, organize the data into training, testing, and validation sets, and prepare it for analysis.\n",
        "\n",
        "The dataset consists of MRI scans from 60 patients, each stored in separate folders. We will:\n",
        "\n",
        "1. Download the dataset, which is provided as a ZIP file.\n",
        "2. Extract the contents of the ZIP file.\n",
        "3. Randomly allocate 40 patient folders to a training set, 10 to a testing set, and the remaining 10 to a validation set, ensuring reproducibility by setting a random seed.\n"
      ],
      "metadata": {
        "id": "LndoAI0yW304"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYqrQKBKVeXK",
        "outputId": "5b892140-f380-459b-886a-181d29673e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Brain MRI Dataset of Multiple Sclerosis with Consensus Manual Lesion Segmentation and Patient Meta Information.zip\n",
            "Extracted Brain MRI Dataset of Multiple Sclerosis with Consensus Manual Lesion Segmentation and Patient Meta Information.zip to brain_mri_dataset\n",
            "Organized data into train, test, and validation folders.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "N_TRAIN = 40\n",
        "N_TEST = 10\n",
        "\n",
        "# Define the URL of the dataset\n",
        "dataset_url = \"https://data.mendeley.com/public-files/datasets/8bctsm8jz7/files/9356efeb-dcd8-4213-a2d4-8febe9f1a5db/file_downloaded\"\n",
        "zip_filename = \"Brain MRI Dataset of Multiple Sclerosis with Consensus Manual Lesion Segmentation and Patient Meta Information.zip\"\n",
        "extracted_folder = \"brain_mri_dataset\"\n",
        "\n",
        "# Define the root folder for data organization\n",
        "data_folder = \"data\"\n",
        "\n",
        "# Define destination directories under the data folder\n",
        "train_folder = os.path.join(data_folder, \"train\")\n",
        "test_folder = os.path.join(data_folder, \"test\")\n",
        "validation_folder = os.path.join(data_folder, \"validation\")\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Function to download the dataset\n",
        "def download_dataset(url, filename):\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(filename, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    print(f\"Downloaded {filename}\")\n",
        "\n",
        "# Function to extract the dataset\n",
        "def extract_dataset(zip_filename, extract_to):\n",
        "    with ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extracted {zip_filename} to {extract_to}\")\n",
        "\n",
        "# Function to organize patient data into train, test, and validation folders\n",
        "def organize_data(extracted_folder, train_folder, test_folder, validation_folder):\n",
        "    # Create the data folder if it doesn't exist\n",
        "    os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "    # Get the list of patient folders\n",
        "    patient_folders = [folder for folder in os.listdir(extracted_folder) if folder.startswith(\"Patient\")]\n",
        "\n",
        "    # Shuffle the list of patient folders\n",
        "    random.shuffle(patient_folders)\n",
        "\n",
        "    # Split into train, test, and validation\n",
        "    train_patients = patient_folders[:N_TRAIN]\n",
        "    test_patients = patient_folders[N_TRAIN:N_TRAIN+N_TEST]\n",
        "    validation_patients = patient_folders[N_TRAIN+N_TEST:]\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "    os.makedirs(validation_folder, exist_ok=True)\n",
        "\n",
        "    # Move patient folders to respective directories\n",
        "    for patient in train_patients:\n",
        "        shutil.move(os.path.join(extracted_folder, patient), train_folder)\n",
        "\n",
        "    for patient in test_patients:\n",
        "        shutil.move(os.path.join(extracted_folder, patient), test_folder)\n",
        "\n",
        "    for patient in validation_patients:\n",
        "        shutil.move(os.path.join(extracted_folder, patient), validation_folder)\n",
        "\n",
        "    print(\"Organized data into train, test, and validation folders.\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Download the dataset\n",
        "    download_dataset(dataset_url, zip_filename)\n",
        "\n",
        "    # Extract the dataset\n",
        "    extract_dataset(zip_filename, extracted_folder)\n",
        "\n",
        "    # Organize the data into train, test, and validation folders\n",
        "    organize_data(extracted_folder, train_folder, test_folder, validation_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "0RCgVviIVm9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "M Muslim, Ali (2022), “Brain MRI Dataset of Multiple Sclerosis with Consensus Manual Lesion Segmentation and Patient Meta Information”, Mendeley Data, V1, doi: 10.17632/8bctsm8jz7.1"
      ],
      "metadata": {
        "id": "saYIlVIOVmA8"
      }
    }
  ]
}